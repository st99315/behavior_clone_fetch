{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2img(objs, h, w):\n",
    "    image_1d = []\n",
    "    for obj in objs:\n",
    "        image_1d.append(np.fromstring(obj, dtype=np.uint8))\n",
    "    image = np.array(image_1d)\n",
    "    image = image.reshape((h, w, 3))\n",
    "    return image\n",
    "\n",
    "\n",
    "# 設定以 gzip 壓縮\n",
    "compression = tf.python_io.TFRecordCompressionType.GZIP\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename,\n",
    "                                                 options=tf.python_io.TFRecordOptions(compression))\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    # 建立 Example\n",
    "    example = tf.train.Example()\n",
    "\n",
    "    # 解析來自於 TFRecords 檔案的資料\n",
    "    example.ParseFromString(string_record)\n",
    "\n",
    "    gifs, exts, csvs = None, None, None\n",
    "    for i in range(4):\n",
    "        # 取出 image_string 這個 Feature\n",
    "        image_string1 = (example.features.feature['gif_{}'.format(i)].bytes_list.value[:])\n",
    "        image_string2 = (example.features.feature['ext_{}'.format(i)].bytes_list.value[:])\n",
    "\n",
    "        # 取出 label 這個 Feature\n",
    "        label = (example.features.feature['fdb_cmd_{}'.format(i)].float_list.value[:])\n",
    "        \n",
    "        gif = string2img(image_string1, 240, 240)[np.newaxis, :]\n",
    "        ext = string2img(image_string2, 120, 120)[np.newaxis, :]\n",
    "        csv = np.array(label, dtype=np.float32)[np.newaxis, :]\n",
    "        \n",
    "        if gifs is None:\n",
    "            gifs = gif.copy()\n",
    "        else:\n",
    "            gifs = np.append(gifs, gif, axis=0)\n",
    "            \n",
    "        if exts is None:\n",
    "            exts = ext.copy()\n",
    "        else:\n",
    "            exts = np.append(exts, ext, axis=0)\n",
    "            \n",
    "        if csvs is None:\n",
    "            csvs = csv.copy()\n",
    "        else:\n",
    "            csvs = np.append(csvs, csv, axis=0)\n",
    "\n",
    "#     for i in range(4):\n",
    "#         plt.figure(i)\n",
    "#         plt.imshow(gifs[i])\n",
    "#         plt.figure(i+1)\n",
    "#         plt.imshow(exts[i])\n",
    "#         plt.show(block=False)\n",
    "#         plt.pause(0.001)\n",
    "        \n",
    "#     print(gifs.shape, exts.shape, csvs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# 圖片標準尺寸\n",
    "gif_img_size = 240\n",
    "ext_img_size = 120\n",
    "\n",
    "\n",
    "def decode_features(features, slice_num=4):\n",
    "    # convert to my structure\n",
    "    giflist, extlist, csvlist = [], [], []\n",
    "    for i in range(slice_num):\n",
    "        gif = tf.decode_raw(features['external_{}'.format(i)], tf.float32)\n",
    "        gif = tf.reshape(gif, [gif_img_size, gif_img_size, 3])\n",
    "        ext = tf.decode_raw(features['eye_hand_{}'.format(i)], tf.float32)\n",
    "        ext = tf.reshape(ext, [ext_img_size, ext_img_size, 3])\n",
    "        csv = tf.sparse_tensor_to_dense(features['fdb_cmd_{}'.format(i)])\n",
    "        csv = tf.reshape(csv, (21,))\n",
    "        giflist.append(gif)\n",
    "        extlist.append(ext)\n",
    "        csvlist.append(csv)\n",
    "    \n",
    "    gifs = tf.stack(giflist, axis=0)\n",
    "    exts = tf.stack(extlist, axis=0)\n",
    "    csvs = tf.stack(csvlist, axis=0)\n",
    "    return gifs, exts, csvs\n",
    "\n",
    "    \n",
    "def read_and_decode(filename_queue, batch_szie=2, slice_num=4):\n",
    "    # 設定以 gzip 壓縮\n",
    "    compression = tf.python_io.TFRecordCompressionType.GZIP\n",
    "    # 建立 TFRecordReader\n",
    "    reader = tf.TFRecordReader(options=tf.python_io.TFRecordOptions(\n",
    "                    compression))\n",
    "\n",
    "    # read data of tfrecords fom filename queue\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    # make features dict\n",
    "    features={}\n",
    "    for i in range(slice_num):\n",
    "        features['external_{}'.format(i)] = tf.FixedLenFeature([], tf.string)\n",
    "        features['eye_hand_{}'.format(i)] = tf.FixedLenFeature([], tf.string)\n",
    "        features['fdb_cmd_{}'.format(i)] = tf.VarLenFeature(tf.float32)\n",
    "        \n",
    "    # read a example\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "        features=features)\n",
    "    gifs, exts, csvs = decode_features(features, slice_num)\n",
    " \n",
    "    # preprocessing\n",
    "    gifs = gifs / 255.\n",
    "    exts = exts / 255.\n",
    "    fdbs = csvs[..., :11]\n",
    "    cmds = csvs[..., 11:]\n",
    "\n",
    "    # 打散資料順序\n",
    "    gif, ext, fdb, cmd = tf.train.shuffle_batch(\n",
    "        [gifs, exts, fdbs, cmds],\n",
    "        batch_size=batch_szie,\n",
    "        capacity=128,\n",
    "        num_threads=2,\n",
    "        min_after_dequeue=32)\n",
    "    gif = tf.reshape(gif, (batch_szie*slice_num, 240, 240, 3))\n",
    "    ext = tf.reshape(ext, (batch_szie*slice_num, 120, 120, 3))\n",
    "    fdb = tf.reshape(fdb, (batch_szie*slice_num, 11))\n",
    "    cmd = tf.reshape(cmd, (batch_szie*slice_num, 10))\n",
    "    return gif, ext, fdb, cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot reshape a tensor with 345600 elements to shape [8,240,240,3] (1382400 elements) for 'Reshape_39' (op: 'Reshape') with input shapes: [2,4,120,120,3], [4] and with input tensors computed as partial shapes: input[1] = [8,240,240,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/youjun/ipynb_test/test_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot reshape a tensor with 345600 elements to shape [8,240,240,3] (1382400 elements) for 'Reshape_39' (op: 'Reshape') with input shapes: [2,4,120,120,3], [4] and with input tensors computed as partial shapes: input[1] = [8,240,240,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a1bd89fbed72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# 讀取並解析 TFRecords 的資料\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mvalid_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d38cf424ac03>\u001b[0m in \u001b[0;36mread_and_decode\u001b[0;34m(filename_queue, batch_szie, slice_num)\u001b[0m\n\u001b[1;32m     65\u001b[0m         min_after_dequeue=32)\n\u001b[1;32m     66\u001b[0m     \u001b[0mgif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgif\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_szie\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mslice_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_szie\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mslice_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mfdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_szie\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mslice_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_szie\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mslice_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/youjun/ipynb_test/test_env/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6112\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6113\u001b[0;31m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   6114\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6115\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/youjun/ipynb_test/test_env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/youjun/ipynb_test/test_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/youjun/ipynb_test/test_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/youjun/ipynb_test/test_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot reshape a tensor with 345600 elements to shape [8,240,240,3] (1382400 elements) for 'Reshape_39' (op: 'Reshape') with input shapes: [2,4,120,120,3], [4] and with input tensors computed as partial shapes: input[1] = [8,240,240,3]."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def get_all_filenames(dir, shuffle=False, size=None):\n",
    "    # finf all of folder\n",
    "    folders = glob.glob(os.path.join(dir, 'object*'))\n",
    "    # get all of gifs\n",
    "    tfrecords = []\n",
    "    for folder in folders:\n",
    "        tfrecords.append(glob.glob(os.path.join(folder, '*.tfrecords')))\n",
    "    tfrecords = np.concatenate(tfrecords)\n",
    "    # shuffle list\n",
    "    if shuffle: random.shuffle(tfrecords)\n",
    "    return tfrecords\n",
    "\n",
    "train_files = get_all_filenames('../train_data_diff_color_0603/train_data')\n",
    "valid_files = get_all_filenames('../train_data_diff_color_0603/valid_data')\n",
    "\n",
    "# 建立檔名佇列\n",
    "train_queue = tf.train.string_input_producer(\n",
    "    tf.convert_to_tensor(train_files), num_epochs=2)\n",
    "\n",
    "# 建立檔名佇列\n",
    "valid_queue = tf.train.string_input_producer(\n",
    "    tf.convert_to_tensor(valid_files), num_epochs=2)\n",
    "\n",
    "# 讀取並解析 TFRecords 的資料\n",
    "train_batch = read_and_decode(train_queue)\n",
    "valid_batch = read_and_decode(valid_queue)\n",
    "\n",
    "# 初始化變數\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "with tf.Session()  as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    tc = 0\n",
    "    # 示範用的簡單迴圈\n",
    "    while True:\n",
    "        try:\n",
    "            gif_batch, ext_batch, fdb_batch, cmd_batch = sess.run(train_batch)\n",
    "            print(gif_batch.shape, ext_batch.shape, fdb_batch.shape, cmd_batch.shape)\n",
    "            print(cmd_batch)\n",
    "            break\n",
    "            tc += 32\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('t finish', tc)\n",
    "            break\n",
    "    vc = 0\n",
    "    while False:\n",
    "        try:\n",
    "            gif_batch, ext_batch, fdb_batch, cmd_batch = sess.run(valid_batch)\n",
    "            print(gif_batch.shape, ext_batch.shape, fdb_batch.shape, cmd_batch.shape)\n",
    "            vc += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('v finish', vc)\n",
    "            break    \n",
    "            \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
